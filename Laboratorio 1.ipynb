{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Regresión Lineal \n",
    "\n",
    "1.1 El coeficiente “3w2” representa cuanto cambia la variable dependiente “y” por cada unidad adicional de la característica \"X2”. Siendo más específicos, por cada incremento de 1 en “X2”, “y \"aumentara “3W2”\n",
    "1.2 La multicolinealidad es cuando dos o más variables independientes están altamente relacionadas entre sí, causando que sea más dificultosa la tarea de saber cuál de ellos es realmente el responsable del cambio \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TASK 2.0 Preparacion de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploracion de datos inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "filepath = \"dataset_phishing.csv\"\n",
    "dataset = pd.read_csv(filepath)\n",
    "#Exploracion de datos - Inciso 2.0\n",
    "print(\"Distribución inicial de la columna 'status':\")\n",
    "print(dataset['status'].value_counts())\n",
    "print(\"\\nVerificacion de datos nulos\")\n",
    "print(dataset.isnull().sum())\n",
    "print(\"\\nResumen estadistico de los datos\")\n",
    "print(dataset.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding de las columnas (Unicamente de la columna status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding de las columnas\n",
    "# Ignorar la columna URL\n",
    "if 'url' in dataset.columns:\n",
    "    dataset = dataset.drop(columns=['url'])\n",
    "# Codificar la columna status\n",
    "if 'status' in dataset.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    dataset['status'] = label_encoder.fit_transform(dataset['status'])\n",
    "\n",
    "# Mostrar las primeras filas del dataset modificado\n",
    "dataset.head(), dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revision de balanceo de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de las clases en la columna 'status'\n",
    "class_distribution = dataset['status'].value_counts()\n",
    "class_distribution_percentage = dataset['status'].value_counts(normalize=True) * 100\n",
    "\n",
    "class_distribution, class_distribution_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificacion si es necesario el escalamiento de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el rango (mínimo y máximo) de las características numéricas\n",
    "feature_ranges = dataset.drop(columns=['status']).agg(['min', 'max']).T\n",
    "feature_ranges['range'] = feature_ranges['max'] - feature_ranges['min']\n",
    "feature_ranges_sorted = feature_ranges.sort_values('range', ascending=False)\n",
    "feature_ranges_sorted.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamiento de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separar las características y la etiqueta\n",
    "X = dataset.drop(columns=['status'])\n",
    "y = dataset['status']\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir X_scaled de nuevo a un DataFrame para mantener las columnas originales\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Mostrar las primeras filas del dataset escalado\n",
    "X_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el dataset en 80% entrenamiento y 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Mostrar la distribución de clases en los conjuntos\n",
    "train_distribution = y_train.value_counts(normalize=True) * 100\n",
    "test_distribution = y_test.value_counts(normalize=True) * 100\n",
    "\n",
    "X_train.shape, X_test.shape, train_distribution, test_distribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
